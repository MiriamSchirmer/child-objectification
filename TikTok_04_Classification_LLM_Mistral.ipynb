{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPm2+VGP7mpQ1nitWa6u8Qe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["*This notebook applies Mistral classification to the Child Objectification Dataset.*"],"metadata":{"id":"gprVtpxoizbf"}},{"cell_type":"markdown","source":["Install Mistral Inference and Load Model"],"metadata":{"id":"gKs4pOjXivjT"}},{"cell_type":"code","source":["!pip install mistral_inference\n"],"metadata":{"collapsed":true,"id":"6DpoQ_JNyXcc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from huggingface_hub import snapshot_download # Huggingface Login might be necessary depending on your setup\n","from pathlib import Path\n","\n","# Define local model path\n","mistral_models_path = Path.home().joinpath('mistral_models', '7B-Instruct-v0.3')\n","mistral_models_path.mkdir(parents=True, exist_ok=True)\n","\n","# Download necessary model files\n","snapshot_download(\n","    repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",\n","    allow_patterns=[\"params.json\", \"consolidated.safetensors\", \"tokenizer.model.v3\"],\n","    local_dir=mistral_models_path\n",")\n"],"metadata":{"id":"WxpszgbryhZ1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["MULTI PROMPT SETUP"],"metadata":{"id":"qjK_OE3qFJrL"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","import re\n","from tqdm import tqdm\n","\n","from mistral_inference.transformer import Transformer\n","from mistral_inference.generate import generate\n","from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n","from mistral_common.protocol.instruct.messages import UserMessage\n","from mistral_common.protocol.instruct.request import ChatCompletionRequest\n","\n","# Load Mistral Model\n","mistral_models_path = \"/root/mistral_models/7B-Instruct-v0.3\"\n","tokenizer = MistralTokenizer.from_file(f\"{mistral_models_path}/tokenizer.model.v3\")\n","model = Transformer.from_folder(mistral_models_path)\n","\n","# Load comments\n","df = pd.read_excel(\"/INSERT-DATA-PATH.xlsx\")\n","comments = df[\"text\"].tolist()\n","\n","# Define classification prompts\n","prompt_dict = {\n","    \"neutral_zero\": \"\"\"Extract all comments that describe the physical appearance of the child in the video, including those that consist only of emojis.\n","    The comments should specifically refer to the child shown and include observations about their appearance. Only include comments that are positive\n","    or neutral in tone. Ignore any comments that do not reference the child’s physical appearance or visual traits.\n","    Include comments that can be used to describe appearance. Take note that these are TikTok comments, so be aware of TikTok-specific language.\n","    - **1** = Describes physical appearance or body parts or outfit-related things.\n","    - **0** = Does not describe physical appearance (e.g., behavior, voice, actions).\n","\n","    Comment: \"{comment}\"\n","    Classification (ONLY return 0 or 1):\"\"\",\n","\n","    \"neutral_few\": \"\"\"Extract all comments that describe the physical appearance of the child in the video, including those that consist only of emojis.\n","    The comments should specifically refer to the child shown and include observations about their appearance. Only include comments that are positive\n","    or neutral in tone. Ignore any comments that do not reference the child’s physical appearance or visual traits.\n","    Include comments that can be used to describe appearance. Take note that these are TikTok comments, so be aware of TikTok-specific language.\n","    - **1** = Describes physical appearance or body parts or outfit-related things.\n","    - **0** = Does not describe physical appearance (e.g., behavior, voice, actions).\n","\n","    Examples:\n","    - \"She is cute\" → 1\n","    - \"I keep wondering who he looks like. He looks like Harry Potter.\" → 1\n","    - \"The way she says ball is so cute!\" → 0\n","\n","    Comment: \"{comment}\"\n","    Classification (ONLY return 0 or 1):\"\"\",\n","\n","    \"negative_zero\": \"\"\"Identify comments that describe the physical appearance of the child in the video, including those consisting only of emojis.\n","    Focus on language that may be objectifying, overly personal, possessive, sexualizing, diminishing, or otherwise inappropriate in tone.\n","    Take note that these are TikTok comments, so be aware of TikTok-specific language. Exclude comments that are unrelated to the child.\n","    - **1** = Contains objectifying or inappropriate language.\n","    - **0** = Does not.\n","\n","    Comment: \"{comment}\"\n","    Classification (ONLY return 0 or 1):\"\"\",\n","\n","    \"negative_few\": \"\"\"Identify comments that describe the physical appearance of the child in the video, including those consisting only of emojis.\n","    Focus on language that may be objectifying, overly personal, possessive, sexualizing, diminishing, or otherwise inappropriate in tone.\n","    Take note that these are TikTok comments, so be aware of TikTok-specific language. Exclude comments that are unrelated to the child.\n","    - **1** = Contains objectifying or inappropriate language.\n","    - **0** = Does not.\n","\n","    Examples:\n","    - \"What a cute little princess\" → 1\n","    - \"I Love You . SO Much.@\" → 1\n","    - \"She looks adorable today!\" → 0\n","\n","    Comment: \"{comment}\"\n","    Classification (ONLY return 0 or 1):\"\"\"\n","}\n","\n","# Single-Comment Classification Function\n","def classify_comment(comment, prompt):\n","    \"\"\"Classifies a single comment using Mistral.\"\"\"\n","\n","    input_text = prompt.format(comment=comment)\n","    request = ChatCompletionRequest(messages=[UserMessage(content=input_text)])\n","\n","    # Tokenize input\n","    tokens = tokenizer.encode_chat_completion(request).tokens\n","\n","    # Generate output\n","    out_tokens, _ = generate(\n","        [tokens], model, max_tokens=2, temperature=0.1,\n","        eos_id=tokenizer.instruct_tokenizer.tokenizer.eos_id\n","    )\n","\n","    # Decode output\n","    decoded_output = tokenizer.instruct_tokenizer.tokenizer.decode(out_tokens[0]).strip()\n","\n","    # Extract classification (only last 0/1)\n","    classification = re.findall(r\"[01]\", decoded_output)\n","    return classification[-1] if classification else \"Error\"\n","\n","# Create output directory\n","output_dir = \"/INSERT-PATH\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# un Classification for All Prompts\n","for name, prompt in prompt_dict.items():\n","    print(f\"\\n Processing '{name}' prompt...\")\n","\n","    results = []\n","    for idx, comment in tqdm(enumerate(comments), total=len(comments), desc=f\"Processing {name}\"):\n","        classification = classify_comment(comment, prompt)\n","        results.append({\"comment\": comment, \"classification\": classification})\n","\n","        # Print first 10 results for debugging\n","        if idx < 10:\n","            print(f\"Comment: {comment}\")\n","            print(f\"Classification: {classification}\")\n","            print(\"-\" * 30)\n","\n","    # Convert to DataFrame and save\n","    df_results = pd.DataFrame(results)\n","    output_file = os.path.join(output_dir, f\"{name}_Mistral.xlsx\")\n","    df_results.to_excel(output_file, index=False)\n","\n"],"metadata":{"id":"hM8ir46iFNe7"},"execution_count":null,"outputs":[]}]}