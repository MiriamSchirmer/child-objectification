{"cells":[{"cell_type":"markdown","source":["This notebook prepares the data on child objectification for further processing and performs statistical tests."],"metadata":{"id":"sEzM79iEqAos"}},{"cell_type":"markdown","metadata":{"id":"TaUIuW_2YxPA"},"source":["**GET DATA**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PI2swHEQVRep"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-KsXG1EwVW_N"},"outputs":[],"source":["# Load dataset from Drive\n","file_path = \"/INSERT-DATA-PATH.csv\"\n","df = pd.read_csv(file_path)"]},{"cell_type":"markdown","metadata":{"id":"ht-QLuwYY2nz"},"source":["**EXPLORE DATA**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"FI6eqSvtVjJU"},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Xj3otyhVuGW"},"outputs":[],"source":["df.columns"]},{"cell_type":"markdown","source":["DATA OVERVIEW"],"metadata":{"id":"4CCzRMiRlGyN"}},{"cell_type":"code","source":["# Columns of interest\n","columns_of_interest = ['videoid', 'videoauthor', 'commid']\n","\n","# Group by 'sex' and calculate unique counts\n","unique_counts = df.groupby('sex')[columns_of_interest].nunique()\n","\n","# Calculate overall unique counts\n","overall_counts = df[columns_of_interest].nunique()\n","\n","# Compute percentages\n","percentage_unique = unique_counts.div(overall_counts) * 100\n","\n","# Create a summary DataFrame\n","summary_df = unique_counts.copy()\n","for col in columns_of_interest:\n","    summary_df[f\"{col}_percentage\"] = percentage_unique[col]\n","\n","print(summary_df)\n"],"metadata":{"id":"BfalWWDXlGZC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Clean Data First"],"metadata":{"id":"dFCHD66CUef-"}},{"cell_type":"code","source":["pip install emoji"],"metadata":{"id":"tm6vo85UURt_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import re\n","import emoji\n","\n","# Ensure \"text\" column is string and handle NaN values\n","df[\"text\"] = df[\"text\"].astype(str).fillna(\"\")\n","\n","# Function to check if a comment consists only of mentions\n","def is_only_mentions(text):\n","    mention_pattern = r\"^@\\w+(\\s*@\\w+)*$\"  # Matches one or more mentions without other text\n","    return bool(re.fullmatch(mention_pattern, text.strip()))\n","\n","# Function to check if a comment consists only of emojis\n","def is_only_emojis(text):\n","    return all(char in emoji.EMOJI_DATA for char in text.strip())\n","\n","# Count mention-only comments\n","mention_only_count = df[\"text\"].apply(is_only_mentions).sum()\n","mention_only_percentage = (mention_only_count / df.shape[0]) * 100\n","\n","print(f\"Number of mention-only comments: {mention_only_count} ({mention_only_percentage:.2f}%)\")\n","\n","# Remove mention-only comments but keep emoji-only ones\n","df = df[~df[\"text\"].apply(is_only_mentions)]\n","\n","# Save cleaned dataset\n","output_path = \"\"\n","df.to_csv(output_path, index=False, encoding=\"utf-8\")\n","\n"],"metadata":{"id":"zxsdxjTfTz__"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Frequency Plots** (for general appearance and objectification)"],"metadata":{"id":"yWbQI4_Gvw8W"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","import emoji\n","import re\n","\n","# Function to remove emojis from text\n","def remove_emojis(text):\n","    return ''.join(char for char in text if not emoji.is_emoji(char))\n","\n","\n","# Extract matched words, remove emojis, and filter out excluded words\n","def clean_matches(column):\n","    words = [remove_emojis(word) for sublist in df[column].dropna() for word in sublist]\n","    words = [word.lower() for word in words if word.lower() not in excluded_words and word.strip()]\n","    return words\n","\n","appearance_words = clean_matches(\"appearance_matches\")\n","negative_appearance_words = clean_matches(\"negative_appearance_matches\")\n","\n","# Count occurrences\n","appearance_counter = Counter(appearance_words)\n","negative_appearance_counter = Counter(negative_appearance_words)\n","\n","# Get 10 most common words/expressions\n","appearance_top10 = appearance_counter.most_common(10)\n","negative_appearance_top10 = negative_appearance_counter.most_common(10)\n","\n","# Convert to separate lists for plotting\n","appearance_labels, appearance_counts = zip(*appearance_top10)\n","negative_labels, negative_counts = zip(*negative_appearance_top10)\n","\n","# Define max x-axis limits for consistency across plots (first graph gets more space)\n","max_x1 = max(appearance_counts) * 1.2  # More extended x-axis for first plot\n","max_x2 = max(negative_counts) * 1.1  # Standard extension for second plot\n","\n","# Plotting\n","fig, axes = plt.subplots(1, 2, figsize=(13, 5), dpi=120, gridspec_kw={'wspace': 0.1})  # Slightly wider figure\n","\n","# Colors (same color family but distinct shades)\n","color1 = \"#4C72B0\"  # Muted blue\n","color2 = \"#B22222\"  # Deep red\n","\n","# Function to plot bars with labels positioned after the bars\n","def plot_bars(ax, labels, counts, title, color, max_x):\n","    bars = ax.barh(range(len(labels)), counts[::-1], color=color, height=0.6)\n","    ax.set_xlim(0, max_x)  # Set different x-axis limits for the two plots\n","    ax.set_title(title, fontsize=14, fontweight=\"bold\", pad=12)\n","    ax.set_xlabel(\"Frequency\", fontsize=12, labelpad=8)\n","    ax.set_yticks([])  # Remove y-ticks\n","    ax.tick_params(axis=\"y\", left=False)  # Ensure no y-ticks are shown\n","\n","    # Add words inside the graph, positioned after the bars\n","    for i, (bar, label) in enumerate(zip(bars, labels[::-1])):\n","        ax.text(bar.get_width() + max_x * 0.02, i, label, va='center', ha='left', fontsize=10, color=\"black\")\n","\n","# Modify labels before plotting\n","negative_labels = [\"(s)he looks like\" if label == \"he looks like\" else label for label in negative_labels]\n","appearence_labels = [\"(s)he looks like\" if label == \"he looks like\" else label for label in negative_labels]\n","\n","# Define max x-axis limits for consistency across plots\n","max_x = max(max(appearance_counts), max(negative_counts)) * 1.2  # Get the maximum count from both datasets\n","\n","# Plot both bar charts with the same x-axis limits\n","plot_bars(axes[0], appearance_labels, appearance_counts, \"General Appearance-Related Words\", color1, max_x)\n","plot_bars(axes[1], negative_labels, negative_counts, \"Objectification-Related Words\", color2, max_x)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"Vcxmka-2lMlL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Statistical Analysis**"],"metadata":{"id":"Zgs3HJUPD10H"}},{"cell_type":"markdown","source":["Prepare Data"],"metadata":{"id":"0gDlMARVbCE6"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Scatter plot of independent variables vs dependent variable\n","df[\"has_appearance_matches\"] = df[\"appearance_matches\"].apply(lambda x: 1 if x is not None else 0)\n","df[\"has_neg_appearance_matches\"] = df[\"negative_appearance_matches\"].apply(lambda x: 1 if x is not None else 0)\n","\n","# Get the frequency table\n","frequency_table_app = pd.crosstab(index=df[\"has_appearance_matches\"], columns=\"count\")\n","\n","# Print the table\n","print(frequency_table_app)\n","\n","frequency_table_app_neg = pd.crosstab(index=df[\"has_neg_appearance_matches\"], columns=\"count\")\n","print(frequency_table_app_neg)"],"metadata":{"id":"WCx7wHj-D1kP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Group by Video"],"metadata":{"id":"ReCssDnqbFaM"}},{"cell_type":"code","source":["# Group by 'videoid' and sum 'has_appearance_matches'\n","appearance_summary = df.groupby('videoid')['has_appearance_matches'].sum().reset_index()\n","appearance_summary = appearance_summary.rename(columns={'has_appearance_matches': 'appearance_match_count'})\n","\n","# Group by 'videoid' and sum 'has_neg_appearance_matches'\n","neg_appearance_summary = df.groupby('videoid')['has_neg_appearance_matches'].sum().reset_index()\n","neg_appearance_summary = neg_appearance_summary.rename(columns={'has_neg_appearance_matches': 'neg_appearance_match_count'})\n","\n","# Merge the two summaries on 'videoid'\n","summary_df = appearance_summary.merge(neg_appearance_summary, on='videoid', how='left')\n","\n","# Fill NaN values with 0 (in case there are no negative appearance matches for some videos)\n","summary_df.fillna(0, inplace=True)\n","\n","# Display the result\n","print(summary_df.head())\n","\n"],"metadata":{"id":"3H19_vAfUiY_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get descriptive statistics\n","summary_stats = summary_df[['appearance_match_count', 'neg_appearance_match_count']].describe()\n","print(summary_stats)\n"],"metadata":{"id":"XHAnuHBoVkUb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Add Metadata"],"metadata":{"id":"OizAVRjWsHUD"}},{"cell_type":"code","source":["# Aggregate gender by taking the first occurrence\n","video_metadata = df.groupby(\"videoid\").agg({\n","    \"sex\": \"first\",       # Take the first occurrence (assuming gender is consistent per video)\n","    \"n_downl\": \"sum\",     # Sum downloads for each video\n","    \"n_likes\": \"sum\",     # Sum likes for each video\n","    \"n_comms\": \"sum\"      # Sum comments for each video\n","}).reset_index()\n"],"metadata":{"id":"AB_XISHBWpwe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Merge the aggregated metadata with summary_df on 'videoid'\n","summary_df = summary_df.merge(video_metadata, on=\"videoid\", how=\"left\")\n","\n","# Check the updated dataframe\n","print(summary_df.head())\n"],"metadata":{"id":"BLz0uCp4Wq8J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Exclude rows where sex == \"both\"\n","summary_df = summary_df[summary_df[\"sex\"] != \"b\"]\n","\n","# Verify changes\n","print(summary_df[\"sex\"].value_counts())\n","\n","# Save the updated DataFrame as an Excel file with UTF-8 encoding\n","output_path = \"/content/drive/MyDrive/TikTok_Harm_Paper/summarized_df_for_stats.xlsx\"\n","summary_df.to_excel(output_path, index=False, engine=\"openpyxl\")"],"metadata":{"id":"sSZNgWw4cF8p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**NEG BINOMIAL REG with INTERACTION**"],"metadata":{"id":"2_nFdShUkSh6"}},{"cell_type":"code","source":["import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","\n","# Interaction model for appearance-related comments\n","model_appearance_interaction = smf.glm(\n","    formula=\"appearance_match_count ~ sex * n_downl + sex * n_comms\",\n","    data=summary_df,\n","    family=sm.families.NegativeBinomial()\n",").fit()\n","\n","# Interaction model for objectification-related comments\n","model_objectification_interaction = smf.glm(\n","    formula=\"neg_appearance_match_count ~ sex * n_downl + sex * n_comms\",\n","    data=summary_df,\n","    family=sm.families.NegativeBinomial()\n",").fit()\n","\n","# Print summaries\n","print(\"Negative Binomial Regression for Appearance-Related Comments:\")\n","print(model_appearance_interaction.summary())\n","\n","print(\"\\nNegative Binomial Regression for Objectification-Related Comments:\")\n","print(model_objectification_interaction.summary())\n"],"metadata":{"id":"D-iupIlCkSLn"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNYTc80KbbinOR/D2T0Hlh7"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}